<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>彩色影像轉紅外線影像</title>
    <link href="/2023/07/17/rgb2IR/"/>
    <url>/2023/07/17/rgb2IR/</url>
    
    <content type="html"><![CDATA[<h1 id="彩色影像轉紅外線影像"><a href="#彩色影像轉紅外線影像" class="headerlink" title="彩色影像轉紅外線影像"></a>彩色影像轉紅外線影像</h1><h3 id="論文標題"><a href="#論文標題" class="headerlink" title="論文標題"></a>論文標題</h3><p>InfraKDGAN: Attribute-Aware Object-Specific Knowledge Distillation Generative Model for Visible-to-Infrared Image Translation</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>這項專案的目的是開發一種先進的技術，能夠在不使用熱成像儀的情況下，將普通彩色影像轉換成紅外線影像，使得任何普通的彩色相機都能夠具備紅外線檢測和成像的功能。這樣一來，使用者就能夠以相對低廉的價格，獲得紅外線影像的能力，並應用於各種領域，例如安防、醫學、能源等。</p><h3 id="簡介"><a href="#簡介" class="headerlink" title="簡介"></a>簡介</h3><p>我們提出了一種新穎的方法InfraKDGAN，結合生成對抗網絡(GANs)和知識蒸餾(KD)技術，以生成高品質IR圖像。我們引入了空間意識和屬性意識概念，逐步提升老師生成器的能力，改進學生生成器的性能。同時使用小波轉換進行KD的教學。在KAIST公開數據集上，與目前最新進的方法相比SSIM提升12.7%，LPIPS下降24.2%。這項研究對於擴大IR圖像數據集並提升深度學習算法在IR任務中的表現具有重要意義。</p><h2 id="提出方法"><a href="#提出方法" class="headerlink" title="提出方法"></a>提出方法</h2><h3 id="InfraKDGAN-Architecture"><a href="#InfraKDGAN-Architecture" class="headerlink" title="InfraKDGAN Architecture"></a>InfraKDGAN Architecture</h3><p><img src="/img/rgb2IR%E6%9E%B6%E6%A7%8B%E5%9C%96.png"></p><h3 id="Special-aware"><a href="#Special-aware" class="headerlink" title="Special-aware"></a>Special-aware</h3><p>我們將物件的位置資訊作為附加的輸入特徵提供給生成模型，使用一個預先訓練好的物件偵測模型對原始可見光圖像進行處理，獲得指定物件在圖像中的位置資訊，在我們的實驗中使用YOLOv8預訓練模型作為物件偵測模型。然後，生成一張高斯熱圖像，其中指定物件位置上的像素值較高，形成類似於熱點的效果，他能夠讓生成器知道那些位置需要關注。接下來，將可見光圖像和高斯熱圖像水平串接起來，作為老師生成器和學生生成器的輸入。<br><img src="/img/special_aware1.jpg"><br><img src="/img/special_aware2.jpg"></p><h3 id="Attribute-aware"><a href="#Attribute-aware" class="headerlink" title="Attribute-aware"></a>Attribute-aware</h3><p>我們觀察到，在生成夜晚圖像時，模型的表現較白天差。這可能是因為夜晚的可見光圖像資訊本來就比白天要稀少。為了讓模型能從可見光圖像中提取更多有用的資訊並嵌入至模型中，我們提出了一個新的方法，將白天夜晚特徵作為屬性特徵。具體而言，我們使用遷移學習在MobileNet-v2模型上訓練了一個能夠區分白天和夜晚的分類器。我們將可見光圖像輸入到分類器中，並提取分類器最後一層的特徵作為屬性資訊。這個屬性資訊可以被視為一個特徵向量，代表圖像屬性中白天或夜晚的特徵。接下來，我們將這個特徵向量嵌入到生成器和判別器中，以實現屬性感知。<br><img src="/img/attribute_aware.jpg"></p><h3 id="Objective-Function"><a href="#Objective-Function" class="headerlink" title="Objective Function"></a>Objective Function</h3><h4 id="Teacher-loss"><a href="#Teacher-loss" class="headerlink" title="Teacher loss"></a>Teacher loss</h4><p><img src="/img/teacher_loss.png"></p><h4 id="Student-loss"><a href="#Student-loss" class="headerlink" title="Student loss"></a>Student loss</h4><p><img src="/img/student_loss.png"></p><h4 id="Wavelet-transform"><a href="#Wavelet-transform" class="headerlink" title="Wavelet transform"></a>Wavelet transform</h4><p>最近的知識蒸餾研究表明，對老師與學生模型的輸出圖片使用小波轉換，轉換為低頻以及高頻特徵後，只對高頻特徵蒸餾有助於老師模型的學習。實驗指出可見光影像ground-truth與生成圖片的高頻L1距離會比低頻L1距離高出不少，這證明對於提取可見光影像高頻資訊會比低頻資訊來的有效。但是以往有關小波轉換知識蒸餾的研究都是針對可見光影像來，並沒有紅外線影像的研究。可見光影像相較於紅外線熱影像細節的部分較多，也就是高頻的特徵較為重要。不過我們以實驗證明，這項概念並不適用於紅外線影像，我們推斷，紅外線影像的平滑部分較多，所以計算出的低頻L1距離會比高頻L1距離還要大。這並不代表高頻部分不重要，而是在熱影像中，是否將低頻和高頻同時納入考量需要視情況而定。</p><h5 id="3-level-wavelet-transform"><a href="#3-level-wavelet-transform" class="headerlink" title="3-level wavelet transform"></a>3-level wavelet transform</h5><p><img src="/img/wavelet_transform1.png"></p><h5 id="Objective-function-of-wavelet-transform"><a href="#Objective-function-of-wavelet-transform" class="headerlink" title="Objective function of wavelet transform"></a>Objective function of wavelet transform</h5><p><img src="/img/wavelet_transform2.png"></p><h5 id="L1-distances-between-wavelet-transformations-of-teacher-student-and-ground-truth"><a href="#L1-distances-between-wavelet-transformations-of-teacher-student-and-ground-truth" class="headerlink" title="L1 distances between wavelet transformations of teacher, student, and ground-truth"></a>L1 distances between wavelet transformations of teacher, student, and ground-truth</h5><p><img src="/img/wavelet_transform3.png"></p><h2 id="實驗結果"><a href="#實驗結果" class="headerlink" title="實驗結果"></a>實驗結果</h2><h3 id="資料集"><a href="#資料集" class="headerlink" title="資料集"></a>資料集</h3><p>我們用於訓練可見光到紅外線影像轉換的資料集是以韓國科學技術院KAIST所蒐集的KAIST Multispectral Pedestrian Detection Benchmark為主。在KAIST資料集中包含95K對可見光-熱影像對，波長7.5~13μm，解析度640×480，且可見光圖像和熱影像都是經過各自時間軸與圖像大小對其而組成的成對影像。其中擁有白天以及夜晚的可見光-熱影像對，此外影像拍攝地場景主要可以概括為KAIST校園內部、一般行駛道路以及建築物繁多的市區這三種場景，圖像中包含的物體大多數為各式車輛、建築物與行人。</p><h3 id="與SOTA-Model比較"><a href="#與SOTA-Model比較" class="headerlink" title="與SOTA Model比較"></a>與SOTA Model比較</h3><p>我們使用SOTA Model InfraGAN[1]作為基準，並且使用兩種不同的圖像評估指標SSIM和LPIPS來評估所提出的方法InfraKDGAN與InfraGAN的性能，其中InfraKDGAN包含老師與學生兩個模型。實驗中的圖像解析度為256×256和512×512。<br><img src="/img/comparison_with_SOTA.png"><br>[1] M. A. Özkanoğlu and S. Ozer, “InfraGAN: A GAN architecture to transfer visible images to infrared domain,” Pattern Recognition Letters, vol. 155, pp. 69-76, 2022.</p><h4 id="InfraKDGAN與SOTA的結果比較圖-含InfraGAN論文中範例"><a href="#InfraKDGAN與SOTA的結果比較圖-含InfraGAN論文中範例" class="headerlink" title="InfraKDGAN與SOTA的結果比較圖(含InfraGAN論文中範例)"></a>InfraKDGAN與SOTA的結果比較圖(含InfraGAN論文中範例)</h4><p><img src="/img/result1.png"></p><h4 id="InfraKDGAN與SOTA的結果比較圖-白天"><a href="#InfraKDGAN與SOTA的結果比較圖-白天" class="headerlink" title="InfraKDGAN與SOTA的結果比較圖(白天)"></a>InfraKDGAN與SOTA的結果比較圖(白天)</h4><p><img src="/img/result2.png"></p><h4 id="InfraKDGAN與SOTA的結果比較圖-夜晚"><a href="#InfraKDGAN與SOTA的結果比較圖-夜晚" class="headerlink" title="InfraKDGAN與SOTA的結果比較圖(夜晚)"></a>InfraKDGAN與SOTA的結果比較圖(夜晚)</h4><p><img src="/img/result3.png"></p><h3 id="結論"><a href="#結論" class="headerlink" title="結論"></a>結論</h3><p>我們提出了一種名為InfraKDGAN的架構，並研究各式方法提升老師模型，我們認為在老師模型加入外部資訊有助於老師模型的訓練，包含special特徵和attribute特徵，也研究如何利用知識蒸餾讓學生模型進一步超越老師模型。<br>最後，我們對我們提出的InfraKDGAN在KAIST資料集上進行了全面的測試。實驗結果與最先進的方法進行了比較，結果顯示InfraKDGAN在SSIM方面提升了12%，而在LPIPS方面則降低了24%。此外，我們的模型在計算複雜度和參數量方面也取得了良好的改善。這些結果表明我們的模型具有卓越的性能。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>指定區域物件生成</title>
    <link href="/2022/11/30/GAN/"/>
    <url>/2022/11/30/GAN/</url>
    
    <content type="html"><![CDATA[<p>本計畫屬於國防部保密範疇…</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>dToF使用者偵測</title>
    <link href="/2022/08/23/dToF/"/>
    <url>/2022/08/23/dToF/</url>
    
    <content type="html"><![CDATA[<p>將dToF(direct-ToF)3D感測晶片技術運用在筆電鏡頭當中，用以來偵測使用者是否正使用筆電。若無使用即可暫時將螢幕關閉，除了能強化資安，更可節省功耗。</p><h3 id="本計畫涉及到保密問題，面試時可斟酌介紹。"><a href="#本計畫涉及到保密問題，面試時可斟酌介紹。" class="headerlink" title="本計畫涉及到保密問題，面試時可斟酌介紹。"></a>本計畫涉及到保密問題，面試時可斟酌介紹。</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>垃圾隨意丟棄科技執法</title>
    <link href="/2021/06/20/trash/"/>
    <url>/2021/06/20/trash/</url>
    
    <content type="html"><![CDATA[<h1 id="垃圾隨意丟棄科技執法"><a href="#垃圾隨意丟棄科技執法" class="headerlink" title="垃圾隨意丟棄科技執法"></a>垃圾隨意丟棄科技執法</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>為保持市容環境，環保局針對重點路段裝設監視錄影設施，以科技執法遏止垃圾隨意丟棄。這是與博遠智能科技(BOVIA)合作的計畫，已實際運用在XX政府環保局。以往取締亂丟垃圾需要人工看影片檢視，費時又費力。這項計畫目的是以科技執法自動化方式記錄一段影像中民眾隨意丟棄垃圾的時間。</p><h2 id="系統流程"><a href="#系統流程" class="headerlink" title="系統流程"></a>系統流程</h2><p><img src="/img/%E5%80%92%E5%9E%83%E5%9C%BE%E6%B5%81%E7%A8%8B%E5%9C%96.png"><br>我們的系統流程能夠自動辨識影片中民眾隨意丟棄垃圾的時間點，包括以下步驟：</p><ol><li>影片輸入：環保局上傳待辨識的影片，並選取ROI。</li><li>影片解析與處理：系統對影片進行解析和處理。</li><li>物件偵測與識別：識別垃圾區域和民眾。</li><li>垃圾丟棄行為檢測：分析行為確定是否隨意丟棄垃圾。</li><li>時間標記：記錄丟棄垃圾的時間點。</li></ol><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="Opticla-Flow"><a href="#Opticla-Flow" class="headerlink" title="Opticla Flow"></a>Opticla Flow</h3><p>連續影像轉換為Optical Flow，再將綠、黃、橘這幾個顏色保留下來，並且去除飽和度較低的顏色，目的是過濾影片中”向下以外”的動作，以及過濾移動速度較慢的物體。<br><img src="/img/opticalflow.png"><br><img src="/img/opticalflow1.gif"><br>補充: Optical Flow(光流)，是將連續影片轉換為方向的方法，不同顏色代表不同方向，越靠中心物體移動速度越慢，物體移動速度越快。</p><p>利用連通域分析(connected component analysis)找出光流連通域，連通域大於設定閥值為疑似垃圾區域，以藍色框標記。<br><img src="/img/%E9%80%A3%E9%80%9A%E5%9F%9F%E5%88%86%E6%9E%90.png"></p><h3 id="Human-Detect-x2F-Keypints-Detect"><a href="#Human-Detect-x2F-Keypints-Detect" class="headerlink" title="Human Detect &#x2F; Keypints Detect"></a>Human Detect &#x2F; Keypints Detect</h3><p>YOLO v5 偵測行人後，利用物件框判斷此行人為移動中或靜止行人。(黑框:移動中行人, 紅框:靜止行人, 黃框:亂丟垃圾行人)，Keypoints model 追蹤行人手腕處 ，利用各種過濾方法排除光流雜訊，只保留疑似垃圾區域。</p><h2 id="結果展示"><a href="#結果展示" class="headerlink" title="結果展示"></a>結果展示</h2><p>影片中左下有一民眾正在隨意丟棄垃圾，疑似垃圾區域以及違規民眾皆已黃框標記。此系統精準捕捉民眾違法行為。<br>在影片中的左下方，我們可以看到一位民眾正在隨意丟棄垃圾，將垃圾從手中扔到地上。這個行為違反了對垃圾處理的相關規定和環境保護法律法規。經過我們系統的準確識別和分析，不僅成功捕捉到這位違規民眾的行為，也將垃圾區域和違規民眾以黃框標記。<br><img src="/img/garbage_demo.gif"></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
